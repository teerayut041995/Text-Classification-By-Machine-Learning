{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from pythainlp.corpus import stopwords\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tag import CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#Load the dataset\n",
    "#df = pd.read_csv(f'w_review_train.csv', sep=';', header=None, names=['review', 'star'])\n",
    "df = pd.read_csv(f'wongnai_reviews2k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  star\n",
       "0  ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...     0\n",
       "1  ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...     0\n",
       "2  วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...     0\n",
       "3  สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...     0\n",
       "4  รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...     0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stop(token_list):\n",
    "    stop_words = set(stopwords.words(\"thai\"))\n",
    "    stopword2 = [',','-',\"'\",'\"','_','(',')',':','?','??','???','????','?????','???????','????????','?????????','?????????','????????????????????','%','ก','The','ต์','แล้','..','ด','ๆดึ๊กๆ','฿)','฿', '^^','^','^^^','ว','ๆๆๆๆๆๆๆๆๆ','ร่????','าา????????????????','เ','ๆๆ????????????????','ๆ','ๆๆ','ๆๆๆ','ๆๆๆๆ','ๆๆๆๆๆ','ๆๆๆๆๆๆ','ๆๆๆๆๆๆๆ','ๆๆๆๆๆๆๆๆ','ๆ!!!','ๆ(','ยยยยยยยยย','ท','<','>',' ','  ','   ','    ','     ','      ','       ','        ','                \\t','ล','ง','กก','น','ส','บอ','รี','ร์','ริ','ฟ','ก้อ','เส','ชาด','วๆ','ออ','บ','ป','รา','อ่ะ','สี','ค','เด','กา','ต','์','อะ','บิ','ฟิ','ม','บุ','พน','กิ','T','ย','รี่','ง.','B','วิ','อ','า','ร','ฮุฮิ','ฟ่าาา','รื่อยๆ','ไห','าาาา','555','the','>_________________<','                     ','                                                                                                                              ','               ','>_________________<','^^?','ยยยยยยยยยยยยยยยยยยยยยย','ๆ????','มม????','ไห','ยยยยย','าาาา','วดี','ๆๆ!!!','ยย','ย่','~*','^_____^*','^___^','+','++','><','าา','<<','จิ','ระ','วว','ช','1.','2.','4.','5.','1','2','3','4','5','6','7','8','9','10','3.','.','วจะ','รึ','ร้่','^_^','ท๊','ยยย','sq','ล์ๆ','น.','/','!!!','มๆ','=','!!','คๆ','           ','ี๊่ยว','้','ดๆ','ฟเฟ่','เบๆ','ฯ', 'บูๆ','รุ้','เด้','!','\\t','ยุ่','่','”','น่','ปต่','^_^','d','าาา','::','็','ะ','฿):','.ๆ','าเเถวๆ','กัจะ','ดดด','กี๊','):','ห','ก้','น้','*','ถ.','น้ล็กๆ','ร้','ยๆ','ป๊','\\r\\n','……????','…','•~•''','๕๕๕๕','๕๕','๑๒๐','ํป','์เล่','์เล','์เปปเป','์เค','็ะ','ๆๆ.','ๆเฟ่','ๆเชงๆ','ๆว้','ๆฟิ','ๆผ','ๆกัร','ๆ ','ๆ.....','ๆ...','ๆ\"','ๆ','ไ้ด้','ไื','ไา้','ไฮเวย์','ไมา','ไก้','ใี','ใา','ให','ใทั้ง','โอกะ','แ้','แ่ซ่','แค้','แข','เ้วย','เ็ป็','เ็','เสิร์','เว่่','เลที่ยะ','เลก็พื้','เลก็ดี','เร้ยยย!!!!','เรืี่','เรี','เม.ย.','เฟ่ต์','เฟิม','เปี่','เปิง','เปลี้ย','เปลี่ย','เปร้ยว','เปรั้ยว','เปรยๆ','เปร','เปปเป','เบล','เบย)','เบยย','เบยยยย','เนล\"','เดิฟท่ี','เซ็ต\"','เชอ','เชฟเฟ','เฉ','เงิบ!!!','฿.','฿+++','ู','ุ','ื่ม','ืำ','ืา','ึะ','ี้','ีว','าาาาาาาา','าาาาาา','าม','า.','ัว','ั','ะะะะะ????????????????????????','ฮ๊','ฮ้ง','ฮี่ฮี่ๆๆ','ฮั้ง','ฮั่ง','ฮัทตั้น','ฮัท','ฮัง','ฮง','อ๊','อื้ม..!!','อือออ','อึ๊งๆ','อี๊','อิ๊ญ','ห์','ห้่','หุหุ','หุ)','หิม','หาว่า','หว๊า','หว','หลืบ','หลาม','หรัล','หมาดๆ','หป','ส้อม','สึ','สะ่ง','สส','สวท.','สต.','ษฯ','ศ์','ศุ','ศศ','ศก.','ศ.','ว๊า','ว้','ว่่่่า','วืช','วล์ๆ','วม','ล์ค(','ล์ค','ล่ง','ล่','ลู่','ลุ','ลู','ลื้มมมมมมม','ลล์\"','ล/ค','ล.','ล\"','ร์เร','ร์เนีย','ร์เดิร์ฟอิ','ร์อิ','ร์)','ร๋ๆ','ร๊า','ร้แย','ร่','~_~',' (','~_~','yukke','yogurt','________','__','^^~','^^)','^^\"','^.^)','^....^','@','?ๆ','????????????????????????','??????????','????????)','????:','????)','???(','??)','?...(','?..','?(','?!','>_<','>\\<','><~','><!','>','<',';;',';))',';(',';\"(',':)))',':(','990','98.947775','931087','90.','9.00','9.','899','8594','8549','8534943','850','840','820','8077','80.','8.','79','78','77','756','7131','71','699','698','69.','670','6655022','665','653','650','65.','640','63','620','6157254','6.5','6.00','599','5796','57','555555555','55555555','555..','5500','550.','545','540','54','539','51','50.','489','48','470','465','460','450.','450','449','429','400.','4.6','4.5..','395','394','389','379','375','370','37','364','37','364','360','36','357','3569','355','35.','334','3200','320','32','31','309','304','3.7','3.4','3.30','3.1','3..','2900','289','28','270','27','2650','265','26','2555','25.','248','241','24.00','234','229','225','224','22.30','219','209','205','2017','2016','2003','2000','2.5..','2.5','194','1927','190','19.372471','19.30','188','185.','180.','18.99','18.30','17.5','165.','164','1600','16.99','159','150.','147','145.','145','14.30','14.00','135','1300','13.00','120.','12.','118','11.45','11.30','1090','1080','108','100.','10..','1.30','1.3..','1.2..','096','0957235785','091','09.00','089','089','084','083','0819591628','080','07.00','05','03.30','02','000.','0.5','..วรัญ','..????','...อื่มมม','....^^','........','.......','-nutty','-Toast','-Special','-Roll','-Pudding','-Lava','-Icecream','-Half','-Eleven','-Breadstick','+คื่น','++)','*******','))',')\"','(ใส้','(เอ๋...','(เลิฟๆ','(มั้ง?)','(ปิง','(นำ้','%***','%)','\"เฟ','\"เบ','\"เชล','\"ฮัน','\"อู๋','\"..','\".','!\"','!!!????????????????????','!!!?','!!!)','!!!!^^*)','','!!!!!!','!!!','                                                           ','                                 ','                          ','                 ','                 ','••','’','ๆ..','5555', '19', '30','25','scoop']\n",
    "    stopword3 = [''];\n",
    "    filtered_sentence = []\n",
    "    for w in token_list:\n",
    "        #if w not in stop_words and w not in stopword2:\n",
    "        if w not in stopword2:\n",
    "        #if w not in stopword3:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in range(0, len(df)):\n",
    "    all_words = []\n",
    "    words = word_tokenize(df['reviews'][i])\n",
    "    words = word_stop(words)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "    documents.append(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = []\n",
    "\n",
    "# allowed_word_types = [\"A\",\"V\",\"X\"]\n",
    "# ct = CRFTagger()\n",
    "# ct.set_model_file('model.crf.tagger')\n",
    "\n",
    "# for i in range(0, len(df)):\n",
    "#     all_words = []\n",
    "#     words = word_tokenize(df['reviews'][i])\n",
    "#     words = word_stop(words)\n",
    "#     pos = ct.tag_sents([words])\n",
    "\n",
    "#     for w in pos[0]:\n",
    "#         if w[1][0] in allowed_word_types:\n",
    "#             all_words.append(w[0])\n",
    "#     documents.append(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ไม่รู้', 'จะ', 'ใจร้าย', 'ไป', 'รึเปล่า', 'แต่', 'ไม่อร่อย', 'ค่ะ', 'Chocolate', 'ที่', 'ให้', 'มา', 'สำหรับ', 'จิ้ม', 'เย็น', 'ได้', 'โล่', 'ไม่มี', 'ไฟ', 'อัง', 'มา', 'ให้', 'ด้วย', 'ค่ะ', 'ใส่', 'ถ้วย', 'มา', 'เฉย', 'โฆษณา', 'ว่า', 'เป็น', 'chocolate', 'มาจาก', 'Swiss', 'แต่', 'หวาน', 'มาก', 'ประมาณ', 'ว่า', 'เอา', 'อะไร', 'ไป', 'จิ้ม', 'ไม่ได้', 'เลย', 'เครื่อง', 'ที่', 'ใช้', 'จิ้ม', 'เห่', 'มาก', 'Waffle', 'แข็ง', 'กรอบ', 'ส่วน', 'ราว', 'นี่', 'ก็', 'หวาน', 'สุด', 'บวก', 'กับ', 'chocolate', 'ที่', 'หวาน', 'อยู่', 'แล้ว', 'แทบตาย', 'เลย', 'ทีเดียว', 'ไป', 'ลอง', 'กัน', 'ได้', 'ค่ะ', 'ลักษณะ', 'ร้าน', 'เป็น', 'ร้าน', 'คาเฟ่', 'เล็ก', 'ริม', 'ทางใน', 'ห้าง', 'มี', 'เก้าอี้นั่ง', 'ได้', 'ประมาณ', 'ที่', 'ค่ะ', 'ราคาขาย', 'ไม่', 'แพง', 'มาก', 'สำหรับ', 'ฟอง', 'ดู', 'แต่', 'ก็', 'ไม่ได้', 'ถูก', 'ค่ะ']\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tfidf = [\" \".join(review) for review in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ Chocolate ที่ ให้ มา สำหรับ จิ้ม เย็น ได้ โล่ ไม่มี ไฟ อัง มา ให้ ด้วย ค่ะ ใส่ ถ้วย มา เฉย โฆษณา ว่า เป็น chocolate มาจาก Swiss แต่ หวาน มาก ประมาณ ว่า เอา อะไร ไป จิ้ม ไม่ได้ เลย เครื่อง ที่ ใช้ จิ้ม เห่ มาก Waffle แข็ง กรอบ ส่วน ราว นี่ ก็ หวาน สุด บวก กับ chocolate ที่ หวาน อยู่ แล้ว แทบตาย เลย ทีเดียว ไป ลอง กัน ได้ ค่ะ ลักษณะ ร้าน เป็น ร้าน คาเฟ่ เล็ก ริม ทางใน ห้าง มี เก้าอี้นั่ง ได้ ประมาณ ที่ ค่ะ ราคาขาย ไม่ แพง มาก สำหรับ ฟอง ดู แต่ ก็ ไม่ได้ ถูก ค่ะ\n"
     ]
    }
   ],
   "source": [
    "print(document_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>star</th>\n",
       "      <th>review_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ขอ ออกความเห็น แบบ ตรงไปตรงมา นะ ครับ ... ผม ไ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...</td>\n",
       "      <td>0</td>\n",
       "      <td>วันนี้ ไป ทาน มา chocolate หวาน เลี่ยน เกินไป ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...</td>\n",
       "      <td>0</td>\n",
       "      <td>สวัสดี ค่ะ เพื่อน ชาว นักกิน ทุกคน ไม่ได้ เจอก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...</td>\n",
       "      <td>0</td>\n",
       "      <td>วิว ใน ครั้งนี้ ไม่ใช่ สเต็ก ใน ร้าน steak lao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  star  \\\n",
       "0  ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...     0   \n",
       "1  ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...     0   \n",
       "2  วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...     0   \n",
       "3  สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...     0   \n",
       "4  รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...     0   \n",
       "\n",
       "                                          review_cut  \n",
       "0  ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ C...  \n",
       "1  ขอ ออกความเห็น แบบ ตรงไปตรงมา นะ ครับ ... ผม ไ...  \n",
       "2  วันนี้ ไป ทาน มา chocolate หวาน เลี่ยน เกินไป ...  \n",
       "3  สวัสดี ค่ะ เพื่อน ชาว นักกิน ทุกคน ไม่ได้ เจอก...  \n",
       "4  วิว ใน ครั้งนี้ ไม่ใช่ สเต็ก ใน ร้าน steak lao...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_cut'] = document_tfidf\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>star</th>\n",
       "      <th>review_cut</th>\n",
       "      <th>text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ C...</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ขอ ออกความเห็น แบบ ตรงไปตรงมา นะ ครับ ... ผม ไ...</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...</td>\n",
       "      <td>0</td>\n",
       "      <td>วันนี้ ไป ทาน มา chocolate หวาน เลี่ยน เกินไป ...</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...</td>\n",
       "      <td>0</td>\n",
       "      <td>สวัสดี ค่ะ เพื่อน ชาว นักกิน ทุกคน ไม่ได้ เจอก...</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...</td>\n",
       "      <td>0</td>\n",
       "      <td>วิว ใน ครั้งนี้ ไม่ใช่ สเต็ก ใน ร้าน steak lao...</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  star  \\\n",
       "0  ไม่รู้จะใจร้ายไปรึเปล่า แต่ไม่อร่อยอ่ะค่ะ\\r\\n\\...     0   \n",
       "1  ขอออกความเห็นแบบตรงไปตรงมานะครับ...\\r\\n\\r\\nผมไ...     0   \n",
       "2  วันนี้ไปทานมา. chocolateหวานเลี่ยนเกินไปค่ะ ตั...     0   \n",
       "3  สวัสดีค่ะ เพื่อนๆชาวนักกินทุกคน^^\\r\\nไม่ได้เจอ...     0   \n",
       "4  รีวิวในครั้งนี้ไม่ใช่สเต็กในร้าน steak lao นะค...     0   \n",
       "\n",
       "                                          review_cut  text length  \n",
       "0  ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ C...          508  \n",
       "1  ขอ ออกความเห็น แบบ ตรงไปตรงมา นะ ครับ ... ผม ไ...          391  \n",
       "2  วันนี้ ไป ทาน มา chocolate หวาน เลี่ยน เกินไป ...          239  \n",
       "3  สวัสดี ค่ะ เพื่อน ชาว นักกิน ทุกคน ไม่ได้ เจอก...         1824  \n",
       "4  วิว ใน ครั้งนี้ ไม่ใช่ สเต็ก ใน ร้าน steak lao...          637  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text length'] = df['review_cut'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review_cut']\n",
    "y = df['star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ไม่รู้ จะ ใจร้าย ไป รึเปล่า แต่ ไม่อร่อย ค่ะ Chocolate ที่ ให้ มา สำหรับ จิ้ม เย็น ได้ โล่ ไม่มี ไฟ อัง มา ให้ ด้วย ค่ะ ใส่ ถ้วย มา เฉย โฆษณา ว่า เป็น chocolate มาจาก Swiss แต่ หวาน มาก ประมาณ ว่า เอา อะไร ไป จิ้ม ไม่ได้ เลย เครื่อง ที่ ใช้ จิ้ม เห่ มาก Waffle แข็ง กรอบ ส่วน ราว นี่ ก็ หวาน สุด บวก กับ chocolate ที่ หวาน อยู่ แล้ว แทบตาย เลย ทีเดียว ไป ลอง กัน ได้ ค่ะ ลักษณะ ร้าน เป็น ร้าน คาเฟ่ เล็ก ริม ทางใน ห้าง มี เก้าอี้นั่ง ได้ ประมาณ ที่ ค่ะ ราคาขาย ไม่ แพง มาก สำหรับ ฟอง ดู แต่ ก็ ไม่ได้ ถูก ค่ะ'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer(lowercase=True,min_df=2).fit(df['review_cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_vect = count_vect.transform(df['review_cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '05',\n",
       " '053',\n",
       " '07',\n",
       " '081',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '105',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '1112',\n",
       " '1122',\n",
       " '115',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '125',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '139',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '155',\n",
       " '16',\n",
       " '160',\n",
       " '165',\n",
       " '169',\n",
       " '17',\n",
       " '170',\n",
       " '175',\n",
       " '179',\n",
       " '18',\n",
       " '180',\n",
       " '185',\n",
       " '189',\n",
       " '19',\n",
       " '195',\n",
       " '199',\n",
       " '20',\n",
       " '200',\n",
       " '2008',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2017',\n",
       " '21',\n",
       " '210',\n",
       " '22',\n",
       " '220',\n",
       " '23',\n",
       " '230',\n",
       " '239',\n",
       " '24',\n",
       " '240',\n",
       " '249',\n",
       " '250',\n",
       " '2557',\n",
       " '2560',\n",
       " '259',\n",
       " '260',\n",
       " '27',\n",
       " '280',\n",
       " '29',\n",
       " '290',\n",
       " '295',\n",
       " '299',\n",
       " '30',\n",
       " '300',\n",
       " '315',\n",
       " '325715429710',\n",
       " '34',\n",
       " '340',\n",
       " '349',\n",
       " '35',\n",
       " '350',\n",
       " '351',\n",
       " '38',\n",
       " '380',\n",
       " '385',\n",
       " '39',\n",
       " '390',\n",
       " '399',\n",
       " '40',\n",
       " '400',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '430',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '479',\n",
       " '480',\n",
       " '49',\n",
       " '499',\n",
       " '50',\n",
       " '500',\n",
       " '53',\n",
       " '530',\n",
       " '55',\n",
       " '55555',\n",
       " '555555',\n",
       " '5555555',\n",
       " '56',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '600',\n",
       " '65',\n",
       " '69',\n",
       " '690',\n",
       " '70',\n",
       " '700',\n",
       " '75',\n",
       " '750',\n",
       " '760',\n",
       " '80',\n",
       " '800',\n",
       " '85',\n",
       " '860',\n",
       " '87',\n",
       " '880',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '95',\n",
       " '99',\n",
       " '999',\n",
       " '__',\n",
       " '___',\n",
       " '____',\n",
       " 'abc',\n",
       " 'add',\n",
       " 'adley',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'air',\n",
       " 'ais',\n",
       " 'all',\n",
       " 'americano',\n",
       " 'anago',\n",
       " 'and',\n",
       " 'app',\n",
       " 'appetizer',\n",
       " 'apple',\n",
       " 'april',\n",
       " 'art',\n",
       " 'at',\n",
       " 'avenue',\n",
       " 'baby',\n",
       " 'bacon',\n",
       " 'bakery',\n",
       " 'ball',\n",
       " 'banana',\n",
       " 'bang',\n",
       " 'bangkok',\n",
       " 'bangna',\n",
       " 'banoffee',\n",
       " 'bar',\n",
       " 'bbq',\n",
       " 'beans',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'benedict',\n",
       " 'berries',\n",
       " 'berry',\n",
       " 'best',\n",
       " 'big',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blanc',\n",
       " 'blend',\n",
       " 'bloc',\n",
       " 'blue',\n",
       " 'blueberry',\n",
       " 'bone',\n",
       " 'bread',\n",
       " 'breakfast',\n",
       " 'bright',\n",
       " 'brownie',\n",
       " 'bruschetta',\n",
       " 'brut',\n",
       " 'bts',\n",
       " 'buffet',\n",
       " 'burger',\n",
       " 'buri',\n",
       " 'buttercup',\n",
       " 'by',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'call',\n",
       " 'caltex',\n",
       " 'canadian',\n",
       " 'cappuccino',\n",
       " 'car',\n",
       " 'caramel',\n",
       " 'carbonara',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carte',\n",
       " 'cat',\n",
       " 'cdc',\n",
       " 'center',\n",
       " 'central',\n",
       " 'charge',\n",
       " 'chat',\n",
       " 'cheddar',\n",
       " 'cheese',\n",
       " 'chef',\n",
       " 'chiangmai',\n",
       " 'chicken',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilli',\n",
       " 'chip',\n",
       " 'choc',\n",
       " 'choco',\n",
       " 'chocolate',\n",
       " 'chonburi',\n",
       " 'choux',\n",
       " 'circle',\n",
       " 'citibank',\n",
       " 'classic',\n",
       " 'click',\n",
       " 'club',\n",
       " 'cocktail',\n",
       " 'coconut',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'com',\n",
       " 'company',\n",
       " 'complex',\n",
       " 'concept',\n",
       " 'confirm',\n",
       " 'cook',\n",
       " 'cost',\n",
       " 'counter',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'crepe',\n",
       " 'crumble',\n",
       " 'ctw',\n",
       " 'cuisine',\n",
       " 'cup',\n",
       " 'cupcake',\n",
       " 'curry',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'de',\n",
       " 'deep',\n",
       " 'delivery',\n",
       " 'den',\n",
       " 'design',\n",
       " 'dessert',\n",
       " 'desserts',\n",
       " 'digital',\n",
       " 'dinner',\n",
       " 'dish',\n",
       " 'don',\n",
       " 'done',\n",
       " 'double',\n",
       " 'drink',\n",
       " 'drop',\n",
       " 'dtac',\n",
       " 'duck',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'egg',\n",
       " 'embassy',\n",
       " 'enjoy',\n",
       " 'espresso',\n",
       " 'esso',\n",
       " 'event',\n",
       " 'extra',\n",
       " 'eye',\n",
       " 'facebook',\n",
       " 'family',\n",
       " 'fanpage',\n",
       " 'fat',\n",
       " 'festival',\n",
       " 'fettuchini',\n",
       " 'fi',\n",
       " 'fillet',\n",
       " 'fin',\n",
       " 'fine',\n",
       " 'fish',\n",
       " 'flower',\n",
       " 'foie',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'for',\n",
       " 'four',\n",
       " 'freddo',\n",
       " 'free',\n",
       " 'french',\n",
       " 'fresh',\n",
       " 'fried',\n",
       " 'fruit',\n",
       " 'fuji',\n",
       " 'full',\n",
       " 'fusion',\n",
       " 'future',\n",
       " 'garden',\n",
       " 'gate',\n",
       " 'gateway',\n",
       " 'gift',\n",
       " 'gold',\n",
       " 'google',\n",
       " 'gourmet',\n",
       " 'gps',\n",
       " 'grand',\n",
       " 'grande',\n",
       " 'granita',\n",
       " 'gras',\n",
       " 'green',\n",
       " 'grill',\n",
       " 'grilled',\n",
       " 'ham',\n",
       " 'have',\n",
       " 'healthy',\n",
       " 'heineken',\n",
       " 'high',\n",
       " 'hill',\n",
       " 'home',\n",
       " 'homemade',\n",
       " 'honey',\n",
       " 'hot',\n",
       " 'hotate',\n",
       " 'hotel',\n",
       " 'house',\n",
       " 'http',\n",
       " 'https',\n",
       " 'iberry',\n",
       " 'ice',\n",
       " 'icecream',\n",
       " 'iced',\n",
       " 'id',\n",
       " 'ig',\n",
       " 'import',\n",
       " 'in',\n",
       " 'indoor',\n",
       " 'interesting',\n",
       " 'is',\n",
       " 'it',\n",
       " 'italian',\n",
       " 'japanese',\n",
       " 'jasmine',\n",
       " 'jazz',\n",
       " 'jelly',\n",
       " 'juice',\n",
       " 'just',\n",
       " 'ka',\n",
       " 'kfc',\n",
       " 'king',\n",
       " 'kitchen',\n",
       " 'korean',\n",
       " 'kung',\n",
       " 'kurobuta',\n",
       " 'la',\n",
       " 'lane',\n",
       " 'lanna',\n",
       " 'latte',\n",
       " 'lava',\n",
       " 'lavender',\n",
       " 'layered',\n",
       " 'le',\n",
       " 'lemon',\n",
       " 'lemonade',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'live',\n",
       " 'lobby',\n",
       " 'lobster',\n",
       " 'local',\n",
       " 'log',\n",
       " 'long',\n",
       " 'lounge',\n",
       " 'love',\n",
       " 'lover',\n",
       " 'low',\n",
       " 'lunch',\n",
       " 'macaron',\n",
       " 'macchiato',\n",
       " 'made',\n",
       " 'main',\n",
       " 'maki',\n",
       " 'mall',\n",
       " 'mango',\n",
       " 'map',\n",
       " 'market',\n",
       " 'matcha',\n",
       " 'mbk',\n",
       " 'meal',\n",
       " 'medium',\n",
       " 'mega',\n",
       " 'member',\n",
       " 'menu',\n",
       " 'milk',\n",
       " 'mind',\n",
       " 'mini',\n",
       " 'mint',\n",
       " 'mix',\n",
       " 'mixed',\n",
       " 'mk',\n",
       " 'mode',\n",
       " 'modern',\n",
       " 'mojito',\n",
       " 'momo',\n",
       " 'monkey',\n",
       " 'mont',\n",
       " 'more',\n",
       " 'mos',\n",
       " 'mousse',\n",
       " 'mushroom',\n",
       " 'music',\n",
       " 'must',\n",
       " 'nestl',\n",
       " 'net',\n",
       " 'new',\n",
       " 'newkungpachim',\n",
       " 'nice',\n",
       " 'niche',\n",
       " 'night',\n",
       " 'nigiri',\n",
       " 'no',\n",
       " 'nom',\n",
       " 'noodle',\n",
       " 'not',\n",
       " 'nutella',\n",
       " 'octave',\n",
       " 'of',\n",
       " 'ohsho',\n",
       " 'ok',\n",
       " 'omelette',\n",
       " 'omg',\n",
       " 'on',\n",
       " 'one',\n",
       " 'onion',\n",
       " 'open',\n",
       " 'option',\n",
       " 'orange',\n",
       " 'order',\n",
       " 'oreo',\n",
       " 'original',\n",
       " 'osaka',\n",
       " 'out',\n",
       " 'outdoor',\n",
       " 'pancake',\n",
       " 'paradise',\n",
       " 'paragon',\n",
       " 'parfait',\n",
       " 'paris',\n",
       " 'park',\n",
       " 'parklane',\n",
       " 'parma',\n",
       " 'passage',\n",
       " 'passion',\n",
       " 'pasta',\n",
       " 'pattaya',\n",
       " 'pb',\n",
       " 'pepper',\n",
       " 'peppercorn',\n",
       " 'personal',\n",
       " 'php',\n",
       " 'phyll',\n",
       " 'pie',\n",
       " 'pink',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'plain',\n",
       " 'platter',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'pop',\n",
       " 'pork',\n",
       " 'portico',\n",
       " 'pot',\n",
       " 'potato',\n",
       " 'premium',\n",
       " 'presentation',\n",
       " 'professional',\n",
       " 'profile',\n",
       " 'promotion',\n",
       " 'ps',\n",
       " 'pudding',\n",
       " 'purr',\n",
       " 'qr',\n",
       " 'queen',\n",
       " 'rain',\n",
       " 'rare',\n",
       " 'raspberry',\n",
       " 'recipes',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'red',\n",
       " 'resort',\n",
       " 'restaurant',\n",
       " 'review',\n",
       " 'reward',\n",
       " 'rib',\n",
       " 'rice',\n",
       " 'ring',\n",
       " 'river',\n",
       " 'riverside',\n",
       " 'road',\n",
       " 'rocky',\n",
       " 'roll',\n",
       " 'rooftop',\n",
       " 'room',\n",
       " 'salad',\n",
       " 'salaya',\n",
       " 'salmon',\n",
       " 'salt',\n",
       " 'sandwich',\n",
       " 'sauce',\n",
       " 'sausage',\n",
       " 'sausages',\n",
       " 'savories',\n",
       " 'sc',\n",
       " 'scone',\n",
       " 'seacon',\n",
       " 'seafood',\n",
       " 'season',\n",
       " 'self',\n",
       " 'semi',\n",
       " 'sense',\n",
       " 'serve',\n",
       " 'service',\n",
       " 'set',\n",
       " 'sfree',\n",
       " 'shake',\n",
       " 'shibuya',\n",
       " 'shot',\n",
       " 'shrimp',\n",
       " 'siam',\n",
       " 'side',\n",
       " 'signature',\n",
       " 'silom',\n",
       " 'sirloin',\n",
       " 'size',\n",
       " 'sizzler',\n",
       " 'smoked',\n",
       " 'smoothie',\n",
       " 'smoothies',\n",
       " 'snowfall',\n",
       " 'soda',\n",
       " 'soft',\n",
       " 'sortrel',\n",
       " 'soup',\n",
       " 'sour',\n",
       " 'spaghetti',\n",
       " 'sparkling',\n",
       " 'special',\n",
       " 'spicy',\n",
       " 'spring',\n",
       " 'square',\n",
       " 'starbucks',\n",
       " 'starter',\n",
       " 'steak',\n",
       " 'step',\n",
       " 'stick',\n",
       " 'strawberry',\n",
       " 'street',\n",
       " 'style',\n",
       " 'super',\n",
       " 'superstar',\n",
       " 'surprise',\n",
       " 'sushi',\n",
       " 'sweet',\n",
       " 'swiss',\n",
       " 'syrup',\n",
       " 'tablet',\n",
       " 'take',\n",
       " 'tea',\n",
       " 'tel',\n",
       " 'tempura',\n",
       " 'teriyaki',\n",
       " 'terminal',\n",
       " 'texture',\n",
       " 'thai',\n",
       " 'thb',\n",
       " 'this',\n",
       " 'tiramisu',\n",
       " 'to',\n",
       " 'toast',\n",
       " 'tomato',\n",
       " 'top',\n",
       " 'topping',\n",
       " 'toro',\n",
       " 'tot',\n",
       " 'tower',\n",
       " 'town',\n",
       " 'trio',\n",
       " 'triple',\n",
       " 'tropical',\n",
       " 'try',\n",
       " 'tt',\n",
       " 'tuna',\n",
       " 'turn',\n",
       " 'two',\n",
       " 'up',\n",
       " 'valley',\n",
       " 'value',\n",
       " 'vanilla',\n",
       " 'vat',\n",
       " 'velvet',\n",
       " 'very',\n",
       " 'village',\n",
       " 'vintage',\n",
       " 'vip',\n",
       " 'vista',\n",
       " 'vodka',\n",
       " 'waffle',\n",
       " 'walk',\n",
       " 'wasabi',\n",
       " 'way',\n",
       " 'well',\n",
       " 'western',\n",
       " 'white',\n",
       " 'whopper',\n",
       " 'wi',\n",
       " 'wifi',\n",
       " 'wine',\n",
       " 'winter',\n",
       " 'with',\n",
       " 'wongnai',\n",
       " 'world',\n",
       " 'www',\n",
       " 'xx',\n",
       " 'yogurt',\n",
       " 'york',\n",
       " 'you',\n",
       " 'your',\n",
       " 'zanotti',\n",
       " 'zen',\n",
       " 'zone',\n",
       " 'zuma',\n",
       " 'กก',\n",
       " 'กกระจ',\n",
       " 'กกระเฉด',\n",
       " 'กกลางว',\n",
       " 'กกาด',\n",
       " 'กกาดดอง',\n",
       " 'กข',\n",
       " 'กขม',\n",
       " 'กขล',\n",
       " 'กค',\n",
       " 'กคน',\n",
       " 'กคร',\n",
       " 'กคะแนน',\n",
       " 'กง',\n",
       " 'กงาน',\n",
       " 'กงานต',\n",
       " 'กงานบร',\n",
       " 'กงานเส',\n",
       " 'กจ',\n",
       " 'กจะ',\n",
       " 'กช',\n",
       " 'กชน',\n",
       " 'กชวน',\n",
       " 'กชาย',\n",
       " 'กซ',\n",
       " 'กฎ',\n",
       " 'กฏ',\n",
       " 'กด',\n",
       " 'กต',\n",
       " 'กตา',\n",
       " 'กถ',\n",
       " 'กท',\n",
       " 'กทม',\n",
       " 'กทอง',\n",
       " 'กทะเล',\n",
       " 'กทาย',\n",
       " 'กน',\n",
       " 'กบ',\n",
       " 'กป',\n",
       " 'กปาก',\n",
       " 'กผ',\n",
       " 'กพ',\n",
       " 'กพล',\n",
       " 'กม',\n",
       " 'กย',\n",
       " 'กยาว',\n",
       " 'กร',\n",
       " 'กรณ',\n",
       " 'กรมศ',\n",
       " 'กรยาน',\n",
       " 'กรรม',\n",
       " 'กรรมว',\n",
       " 'กรรเช',\n",
       " 'กรวม',\n",
       " 'กรอ',\n",
       " 'กรอก',\n",
       " 'กรอบ',\n",
       " 'กรอบหน',\n",
       " 'กระ',\n",
       " 'กระจ',\n",
       " 'กระจก',\n",
       " 'กระจกใส',\n",
       " 'กระจาย',\n",
       " 'กระชาก',\n",
       " 'กระชาย',\n",
       " 'กระด',\n",
       " 'กระดอง',\n",
       " 'กระดานดำ',\n",
       " 'กระดาษ',\n",
       " 'กระต',\n",
       " 'กระท',\n",
       " 'กระทะ',\n",
       " 'กระทา',\n",
       " 'กระบ',\n",
       " 'กระบวนการ',\n",
       " 'กระบอก',\n",
       " 'กระป',\n",
       " 'กระวาน',\n",
       " 'กระหน',\n",
       " 'กระหาย',\n",
       " 'กระเจ',\n",
       " 'กระเฉด',\n",
       " 'กระเด',\n",
       " 'กระเท',\n",
       " 'กระเบน',\n",
       " 'กระเป',\n",
       " 'กระเพาะ',\n",
       " 'กระเพาะปลา',\n",
       " 'กระแทก',\n",
       " 'กระแส',\n",
       " 'กระแสลม',\n",
       " 'กราบ',\n",
       " 'กราย',\n",
       " 'กล',\n",
       " 'กลบ',\n",
       " 'กลม',\n",
       " 'กลมกล',\n",
       " 'กลอง',\n",
       " 'กลา',\n",
       " 'กลาง',\n",
       " 'กลางค',\n",
       " 'กลางทาง',\n",
       " 'กลางว',\n",
       " 'กลางเม',\n",
       " 'กลางแจ',\n",
       " 'กลางๆ',\n",
       " 'กลาย',\n",
       " 'กลายเป',\n",
       " 'กว',\n",
       " 'กวน',\n",
       " 'กวนใจ',\n",
       " 'กวย',\n",
       " 'กวาง',\n",
       " 'กวางต',\n",
       " 'กวาด',\n",
       " 'กศ',\n",
       " 'กษ',\n",
       " 'กษณ',\n",
       " 'กษณะ',\n",
       " 'กษา',\n",
       " 'กส',\n",
       " 'กสด',\n",
       " 'กสนาน',\n",
       " 'กสล',\n",
       " 'กสาว',\n",
       " 'กหน',\n",
       " 'กหนา',\n",
       " 'กหยวก',\n",
       " 'กหล',\n",
       " 'กหลาน',\n",
       " 'กหวาน',\n",
       " 'กหวานบ',\n",
       " 'กอ',\n",
       " 'กอง',\n",
       " 'กอบ',\n",
       " 'กอบรม',\n",
       " 'กอย',\n",
       " 'กออก',\n",
       " 'กอาศ',\n",
       " 'กฮวย',\n",
       " 'กะ',\n",
       " 'กะท',\n",
       " 'กะทะ',\n",
       " 'กะป',\n",
       " 'กะพง',\n",
       " 'กะหร',\n",
       " 'กะหล',\n",
       " 'กะเพรา',\n",
       " 'กา',\n",
       " 'กาก',\n",
       " 'กากหม',\n",
       " 'กาง',\n",
       " 'กางเกงขาส',\n",
       " 'กาด',\n",
       " 'กาบ',\n",
       " 'กาย',\n",
       " 'การ',\n",
       " 'การก',\n",
       " 'การควบค',\n",
       " 'การจ',\n",
       " 'การณ',\n",
       " 'การต',\n",
       " 'การตลาด',\n",
       " 'การทำงาน',\n",
       " 'การน',\n",
       " 'การนำ',\n",
       " 'การบร',\n",
       " 'การปร',\n",
       " 'การพ',\n",
       " 'การพา',\n",
       " 'การย',\n",
       " 'การรอคอย',\n",
       " 'การศ',\n",
       " 'การส',\n",
       " 'การเข',\n",
       " 'การเปล',\n",
       " 'การแสดงความค',\n",
       " 'การโยน',\n",
       " 'กาล',\n",
       " 'กาแฟ',\n",
       " 'กาแฟร',\n",
       " 'กาแฟสด',\n",
       " 'กาแฟเย',\n",
       " 'กำ',\n",
       " 'กำก',\n",
       " 'กำล',\n",
       " 'กำหนด',\n",
       " 'กำแพง',\n",
       " 'กำไร',\n",
       " 'กเก',\n",
       " 'กเกด',\n",
       " 'กเกอร',\n",
       " 'กเขม',\n",
       " 'กเคล',\n",
       " 'กเด',\n",
       " 'กเต',\n",
       " 'กเท',\n",
       " 'กเร',\n",
       " 'กเล',\n",
       " 'กเลง',\n",
       " 'กเส',\n",
       " 'กแดง',\n",
       " 'กแถว',\n",
       " 'กแล',\n",
       " 'กโขม',\n",
       " 'กใจ',\n",
       " 'กในใจ',\n",
       " 'กใหญ',\n",
       " 'กไก',\n",
       " 'กได',\n",
       " 'กไทย',\n",
       " 'กไม',\n",
       " 'กๆ',\n",
       " 'ขณะ',\n",
       " 'ขณะท',\n",
       " 'ขณะน',\n",
       " 'ขน',\n",
       " 'ขนม',\n",
       " 'ขนมครก',\n",
       " 'ขนมจ',\n",
       " 'ขนมป',\n",
       " 'ขนมผ',\n",
       " 'ขนมหวาน',\n",
       " 'ขนมเค',\n",
       " 'ขนมเบ',\n",
       " 'ขนมไทย',\n",
       " 'ขนาด',\n",
       " 'ขนาดท',\n",
       " 'ขนาดเล',\n",
       " 'ขนาดใหญ',\n",
       " 'ขนาน',\n",
       " 'ขนาบ',\n",
       " 'ขบวน',\n",
       " 'ขภาพ',\n",
       " 'ขม',\n",
       " 'ขย',\n",
       " 'ขยะ',\n",
       " 'ขยาย',\n",
       " 'ขยายสาขา',\n",
       " 'ขร',\n",
       " 'ขล',\n",
       " 'ขว',\n",
       " 'ขวด',\n",
       " 'ขวบ',\n",
       " 'ขวา',\n",
       " 'ขวาง',\n",
       " 'ขวาม',\n",
       " 'ขอ',\n",
       " 'ของ',\n",
       " 'ของก',\n",
       " 'ของคาว',\n",
       " 'ของจร',\n",
       " 'ของชำ',\n",
       " 'ของด',\n",
       " 'ของธรรมดา',\n",
       " 'ของฝาก',\n",
       " 'ของว',\n",
       " 'ของสด',\n",
       " 'ของหวาน',\n",
       " 'ของเก',\n",
       " 'ของเล',\n",
       " 'ของแถม',\n",
       " 'ของแท',\n",
       " 'ของโปรด',\n",
       " 'ขอนาม',\n",
       " 'ขอนแก',\n",
       " 'ขอบ',\n",
       " 'ขอบค',\n",
       " 'ขอร',\n",
       " 'ขอลา',\n",
       " 'ขออน',\n",
       " 'ขออภ',\n",
       " 'ขอโทษ',\n",
       " 'ขอให',\n",
       " 'ขอไปท',\n",
       " 'ขา',\n",
       " 'ขากล',\n",
       " 'ขาจร',\n",
       " 'ขาด',\n",
       " 'ขาดตกบกพร',\n",
       " 'ขาดสาย',\n",
       " 'ขาดไม',\n",
       " 'ขาประจำ',\n",
       " 'ขาย',\n",
       " 'ขายของ',\n",
       " 'ขายด',\n",
       " 'ขายต',\n",
       " 'ขายบร',\n",
       " 'ขายส',\n",
       " 'ขาว',\n",
       " 'ขาออก',\n",
       " 'ขาเข',\n",
       " 'ขำ',\n",
       " 'ขโมย',\n",
       " 'ขใจ',\n",
       " 'คก',\n",
       " 'คค',\n",
       " 'คคล',\n",
       " 'คง',\n",
       " 'คงจะ',\n",
       " 'คงท',\n",
       " 'คงอย',\n",
       " 'คงเส',\n",
       " 'คณะ',\n",
       " 'คต',\n",
       " 'คตร',\n",
       " 'คน',\n",
       " 'คนกร',\n",
       " 'คนข',\n",
       " 'คนค',\n",
       " 'คนคร',\n",
       " 'คนจ',\n",
       " 'คนซ',\n",
       " 'คนญ',\n",
       " 'คนด',\n",
       " 'คนต',\n",
       " 'คนบ',\n",
       " 'คนป',\n",
       " 'คนม',\n",
       " 'คนร',\n",
       " 'คนละ',\n",
       " 'คนละเร',\n",
       " 'คนอ',\n",
       " 'คนเข',\n",
       " 'คนเด',\n",
       " 'คนเมา',\n",
       " 'คนเรา',\n",
       " 'คนแก',\n",
       " 'คนแนะนำ',\n",
       " 'คนใต',\n",
       " 'คนใน',\n",
       " 'คนไทย',\n",
       " 'คบ',\n",
       " 'คม',\n",
       " 'คย',\n",
       " 'คร',\n",
       " 'ครก',\n",
       " 'ครบ',\n",
       " 'ครบคร',\n",
       " 'ครบถ',\n",
       " 'ครบเคร',\n",
       " 'ครอบคร',\n",
       " 'ครอส',\n",
       " 'ครา',\n",
       " 'คราบ',\n",
       " 'คราว',\n",
       " 'คราวก',\n",
       " 'คราวน',\n",
       " 'คราวหน',\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_names = count_vect.get_feature_names()\n",
    "X_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_vect = pd.DataFrame(X_count_vect.toarray(),columns=X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4244)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>05</th>\n",
       "      <th>053</th>\n",
       "      <th>07</th>\n",
       "      <th>081</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>ไอต</th>\n",
       "      <th>ไอศกร</th>\n",
       "      <th>ไอศคร</th>\n",
       "      <th>ไอเด</th>\n",
       "      <th>ไฮ</th>\n",
       "      <th>ไฮโซ</th>\n",
       "      <th>ๆก</th>\n",
       "      <th>ๆๆ</th>\n",
       "      <th>ๆๆๆ</th>\n",
       "      <th>๕๕๕</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   02   05  053   07  081   09   10  100 ...   ไอต  ไอศกร  ไอศคร  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0    0.0    0.0   \n",
       "\n",
       "   ไอเด   ไฮ  ไฮโซ   ๆก   ๆๆ  ๆๆๆ  ๕๕๕  \n",
       "0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 4244 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv , X_test_cv , y_train_cv , y_test_cv = train_test_split(X_count_vect,y,test_size=0.10,random_state=2499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 18]\n",
      " [ 4 91]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.83      0.89       105\n",
      "          1       0.83      0.96      0.89        95\n",
      "\n",
      "avg / total       0.90      0.89      0.89       200\n",
      "\n",
      "accuracy_score 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report , accuracy_score\n",
    "print(confusion_matrix(y_test_cv, preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test_cv, preds))\n",
    "print(\"accuracy_score\" , accuracy_score(y_test_cv, preds))\n",
    "#print(\"roc_auc_score\" , roc_auc_score(y_test , mnb.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train =  1800  test =  200\n",
      "[[87 18]\n",
      " [ 4 91]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.83      0.89       105\n",
      "          1       0.83      0.96      0.89        95\n",
      "\n",
      "avg / total       0.90      0.89      0.89       200\n",
      "\n",
      "accuracy_score 0.89\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[82 19]\n",
      " [ 2 97]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.81      0.89       101\n",
      "          1       0.84      0.98      0.90        99\n",
      "\n",
      "avg / total       0.91      0.90      0.89       200\n",
      "\n",
      "accuracy_score 0.895\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[76 23]\n",
      " [ 8 93]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.77      0.83        99\n",
      "          1       0.80      0.92      0.86       101\n",
      "\n",
      "avg / total       0.85      0.84      0.84       200\n",
      "\n",
      "accuracy_score 0.845\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[85 20]\n",
      " [ 4 91]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.81      0.88       105\n",
      "          1       0.82      0.96      0.88        95\n",
      "\n",
      "avg / total       0.89      0.88      0.88       200\n",
      "\n",
      "accuracy_score 0.88\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[75 26]\n",
      " [ 3 96]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.74      0.84       101\n",
      "          1       0.79      0.97      0.87        99\n",
      "\n",
      "avg / total       0.88      0.85      0.85       200\n",
      "\n",
      "accuracy_score 0.855\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[81 15]\n",
      " [11 93]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.84      0.86        96\n",
      "          1       0.86      0.89      0.88       104\n",
      "\n",
      "avg / total       0.87      0.87      0.87       200\n",
      "\n",
      "accuracy_score 0.87\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[89 12]\n",
      " [ 9 90]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.88      0.89       101\n",
      "          1       0.88      0.91      0.90        99\n",
      "\n",
      "avg / total       0.90      0.90      0.89       200\n",
      "\n",
      "accuracy_score 0.895\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[77 17]\n",
      " [ 8 98]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.82      0.86        94\n",
      "          1       0.85      0.92      0.89       106\n",
      "\n",
      "avg / total       0.88      0.88      0.87       200\n",
      "\n",
      "accuracy_score 0.875\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[91 14]\n",
      " [ 6 89]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.87      0.90       105\n",
      "          1       0.86      0.94      0.90        95\n",
      "\n",
      "avg / total       0.90      0.90      0.90       200\n",
      "\n",
      "accuracy_score 0.9\n",
      "\n",
      "\n",
      "train =  1800  test =  200\n",
      "[[ 80  13]\n",
      " [  4 103]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90        93\n",
      "          1       0.89      0.96      0.92       107\n",
      "\n",
      "avg / total       0.92      0.92      0.91       200\n",
      "\n",
      "accuracy_score 0.915\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy average >>  88.2\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, random_state=2499, shuffle=True)\n",
    "accuracy_scores = []\n",
    "sum_average = 0\n",
    "for X_train_cv , X_test_cv in kf.split(X_count_vect):\n",
    "    print(\"train = \", len(X_train_cv),\" test = \", len(X_test_cv))\n",
    "    train_data = np.array(X_count_vect)[X_train_cv]\n",
    "    test_data = np.array(X_count_vect)[X_test_cv]\n",
    "    y_train_cv = np.array(y)[X_train_cv]\n",
    "    y_test_cv =  np.array(y)[X_test_cv]\n",
    "    clf_cv = MultinomialNB()\n",
    "    clf_cv.fit(train_data,y_train_cv)\n",
    "    y_pred_cv = clf_cv.predict(test_data)\n",
    "    print(confusion_matrix(y_test_cv, y_pred_cv))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test_cv, y_pred_cv))\n",
    "    print(\"accuracy_score\" , accuracy_score(y_test_cv, y_pred_cv))\n",
    "    print(\"\\n\")\n",
    "    sum_average += accuracy_score(y_test_cv, y_pred_cv)\n",
    "#print(\"roc_auc_score\" , roc_auc_score(y_test , nb.predict_proba(X_test)[:,1]))\n",
    "average = (sum_average/10)*100 \n",
    "print(\"Naive Bayes Accuracy average >> \" , average)\n",
    "print('===============================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Preditction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'food_sent_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้ฮิตมานานในหมู่นักศึกษา มช.ค่ะ (แน่หละ ก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้อาจจะต้องบริการตนเองนิดนึงนะคะ เพราะคนเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้อาหารอร่อยทุกอย่างไม่ว่าจะเป็นส้มตำไก่ท...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านขนมจีนเส้นสด พร้อมอาหารตามสั่งที่นี่ จะเสร...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านก๋วยจั๊บเปิดใหม่ใกล้ ๆ ข่วงสันกำแพง ทางไปว...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src  target                                               text\n",
       "0   w       1  ร้านนี้ฮิตมานานในหมู่นักศึกษา มช.ค่ะ (แน่หละ ก...\n",
       "1   w       1  ร้านนี้อาจจะต้องบริการตนเองนิดนึงนะคะ เพราะคนเ...\n",
       "2   w       1  ร้านนี้อาหารอร่อยทุกอย่างไม่ว่าจะเป็นส้มตำไก่ท...\n",
       "3   w       1  ร้านขนมจีนเส้นสด พร้อมอาหารตามสั่งที่นี่ จะเสร...\n",
       "4   w       1  ร้านก๋วยจั๊บเปิดใหม่ใกล้ ๆ ข่วงสันกำแพง ทางไปว..."
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_test = []\n",
    "for i in range(0, len(df_test)):\n",
    "    all_words = []\n",
    "    words = word_tokenize(df_test['text'][i])\n",
    "    words = word_stop(words)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "    documents_test.append(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tfidf_test = [\" \".join(review) for review in documents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้ฮิตมานานในหมู่นักศึกษา มช.ค่ะ (แน่หละ ก...</td>\n",
       "      <td>ร้าน นี้ ฮิต หมู่ นักศึกษา มช. แน่ หละ มอ นิ ช...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้อาจจะต้องบริการตนเองนิดนึงนะคะ เพราะคนเ...</td>\n",
       "      <td>ร้าน นี้ บริการ นิดนึง นะคะ คน ร้าน อาหาร อร่อ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านนี้อาหารอร่อยทุกอย่างไม่ว่าจะเป็นส้มตำไก่ท...</td>\n",
       "      <td>ร้าน นี้ อาหาร อร่อย ส้มตำ ไก่ทอด สมุนไพร ขนมจ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านขนมจีนเส้นสด พร้อมอาหารตามสั่งที่นี่ จะเสร...</td>\n",
       "      <td>ร้าน ขนมจีน เส้น สด อาหาร สั่ง ที่นี่ ขนมจีน ต...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>ร้านก๋วยจั๊บเปิดใหม่ใกล้ ๆ ข่วงสันกำแพง ทางไปว...</td>\n",
       "      <td>ร้าน ก๋วยจั๊บ ข่วง สัน กำแพง วัด สัน เหนือ ตึก...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  src  target                                               text  \\\n",
       "0   w       1  ร้านนี้ฮิตมานานในหมู่นักศึกษา มช.ค่ะ (แน่หละ ก...   \n",
       "1   w       1  ร้านนี้อาจจะต้องบริการตนเองนิดนึงนะคะ เพราะคนเ...   \n",
       "2   w       1  ร้านนี้อาหารอร่อยทุกอย่างไม่ว่าจะเป็นส้มตำไก่ท...   \n",
       "3   w       1  ร้านขนมจีนเส้นสด พร้อมอาหารตามสั่งที่นี่ จะเสร...   \n",
       "4   w       1  ร้านก๋วยจั๊บเปิดใหม่ใกล้ ๆ ข่วงสันกำแพง ทางไปว...   \n",
       "\n",
       "                                            text_cut  \n",
       "0  ร้าน นี้ ฮิต หมู่ นักศึกษา มช. แน่ หละ มอ นิ ช...  \n",
       "1  ร้าน นี้ บริการ นิดนึง นะคะ คน ร้าน อาหาร อร่อ...  \n",
       "2  ร้าน นี้ อาหาร อร่อย ส้มตำ ไก่ทอด สมุนไพร ขนมจ...  \n",
       "3  ร้าน ขนมจีน เส้น สด อาหาร สั่ง ที่นี่ ขนมจีน ต...  \n",
       "4  ร้าน ก๋วยจั๊บ ข่วง สัน กำแพง วัด สัน เหนือ ตึก...  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text_cut'] = document_tfidf_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['target'][1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ร้านสกปรก ไม่สะอาดเลย\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_review = \"ร้านสกปรก ไม่สะอาดเลย\"\n",
    "print(positive_review)\n",
    "positive_review_transformed = bow_transformer.transform([positive_review])\n",
    "nb.predict(positive_review_transformed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
